{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "Memory usage: 1785159680 (kb)\n",
      "Checkpoint 1\n",
      "Memory usage: 1785159680 (kb)\n",
      "Checkpoint 2\n",
      "Memory usage: 1785159680 (kb)\n"
     ]
    }
   ],
   "source": [
    "import resource\n",
    "\n",
    "print(\"Checkpoint 0\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from pandas.io import sql\n",
    "import sqlite3\n",
    "\n",
    "print(\"Checkpoint 1\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Select only the relevant columns\n",
    "pop_cols = ['AGEP','SEX','HISP','POBP','RAC1P','SCIENGP','SOCP']\n",
    "\n",
    "# Load in all of the ACS2013 data\n",
    "df = pd.concat([pd.read_csv(\"../input/pums/ss13pusa.csv\", usecols=pop_cols),\n",
    "\tpd.read_csv(\"../input/pums/ss13pusb.csv\", usecols=pop_cols)])\n",
    "\n",
    "print(\"Checkpoint 2\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2.1\n",
      "Memory usage: 1785159680 (kb)\n",
      "Checkpoint 2.2\n",
      "Memory usage: 1785159680 (kb)\n",
      "0.0153677466926\n",
      "Checkpoint 2.3\n",
      "Memory usage: 1793794048 (kb)\n",
      "Checkpoint 2.4\n",
      "Memory usage: 2703872000 (kb)\n",
      "Checkpoint 2.5\n",
      "Memory usage: 2703872000 (kb)\n",
      "Checkpoint 2.6\n",
      "Memory usage: 2703872000 (kb)\n",
      "Checkpoint 2.7\n",
      "Memory usage: 2703872000 (kb)\n",
      "Checkpoint 2.8\n",
      "Memory usage: 2703872000 (kb)\n",
      "Checkpoint 3\n",
      "Memory usage: 2703872000 (kb)\n"
     ]
    }
   ],
   "source": [
    "# Recode state into state names\n",
    "oldNewMap = {1: \"Alabama\", 2: \"Alaska\", 4: \"Arizona\", 5: \"Arkansas\", 6: \"California\",\n",
    "8: \"Colorado\", 9: \"Connecticut\", 10: \"Delaware\", 11: \"District_of_Columbia\",\n",
    "12: \"Florida\", 13: \"Georgia\", 15: \"Hawaii\", 16: \"Idaho\", 17: \"Illinois\", 18: \"Indiana\",\n",
    "19: \"Iowa\", 20: \"Kansas\", 21: \"Kentucky\", 22: \"Louisiana\", 23: \"Maine\", 24: \"Maryland\",\n",
    "25: \"Massachusetts\", 26: \"Michigan\", 27: \"Minnesota\", 28: \"Mississippi\", 29: \"Missouri\",\n",
    "30: \"Montana\", 31: \"Nebraska\", 32: \"Nevada\", 33: \"New_Hampshire\", 34: \"New_Mexico\",\n",
    "35: \"New_Jersey\", 36: \"New_York\", 37: \"North_Carolina\", 38: \"North_Dakota\", 39: \"Ohio\",\n",
    "40: \"Oklahoma\", 41: \"Oregon\", 42: \"Pennsylvania\", 44: \"Rhode_Island\", 45: \"South_Carolina\",\n",
    "46: \"South_Dakota\", 47: \"Tennessee\", 48: \"Texas\", 49: \"Utah\", 50: \"Vermont\", 51: \"Virginia\",\n",
    "53: \"Washington\", 54: \"West_Virginia\", 55: \"Wisconsin\", 56: \"Wyoming\"}\n",
    "df['State'] = df['POBP'].map(oldNewMap)\n",
    "\n",
    "# The outcome variable ('SCIENGP') needs to be converted to a binary\n",
    "oldNewMap = {1: 1, 2: 0}\n",
    "df['science_degree'] = df['SCIENGP'].map(oldNewMap)\n",
    "df['science_degree'].fillna(value=0,inplace=True)\n",
    "\n",
    "print(\"Checkpoint 2.1\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Another outcome all college degrees - convert to binary\n",
    "oldNewMap = {1: 1, 2: 1}\n",
    "df['college_degree'] = df['SCIENGP'].map(oldNewMap)\n",
    "df['college_degree'].fillna(value=0,inplace=True)\n",
    "\n",
    "print(\"Checkpoint 2.2\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Another outcome: science occupation\n",
    "# A list of STEM Occupation SOC codes is found here:\n",
    "# http://www.bls.gov/soc/Attachment_C_STEM.pdf\n",
    "\n",
    "science_job_codes = ['113021','119041','119121','151111','151121','151122','151131','151132','151133',\n",
    "                          '151134','151141','151142','151143','151151','151152','151199','152011','152021',\n",
    "                          '152031','152041','152099','171021','171022','172011','172021','172031','172041',\n",
    "                          '172051','172061','172071','172072','172081','172111','172112','172121','172131',\n",
    "                          '172141','172151','172161','172171','172199','173012','173013','173019','173021',\n",
    "                          '173022','173023','173024','173025','173026','173027','173029','173031','191011',\n",
    "                          '191012','191012','191021','191022','191023','191029','191031','191032','191041',\n",
    "                          '191042','191099','192011','192012','192021','192031','192032','192041','192042',\n",
    "                          '192043','192099','194011','194021','194031','194041','194051','194091','194092',\n",
    "                          '194093','251021','251022','251032','251041','251042','251043','251051','251052',\n",
    "                          '251053','251054','414011','419031']\n",
    "\n",
    "df['science_occupation'] = df['SOCP'].isin(science_job_codes).astype(int)\n",
    "    \n",
    "print np.mean(df.science_occupation)\n",
    "\n",
    "print(\"Checkpoint 2.3\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Recoding race to 5 categories\n",
    "def race_recode(row):\n",
    "\tif row['HISP'] > 1:\n",
    "\t\treturn \"Hispanic\"\n",
    "\telif row['RAC1P'] == 1:\n",
    "\t\treturn \"White\"\n",
    "\telif row['RAC1P'] == 2:\n",
    "\t\treturn \"Black\"\n",
    "\telif row['RAC1P'] == 6:\n",
    "\t\treturn \"Asian\"\n",
    "\telse:\n",
    "\t\treturn \"Other\"\n",
    "df['race_recode'] = df.apply(race_recode, axis=1)\n",
    "\n",
    "print(\"Checkpoint 2.4\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# recode the HISP variable for easy readability\n",
    "oldNewMap = {1: \"Not Spanish/Hispanic/Latino\", 2: \"Mexican\", 3: \"Puerto Rican\", 4: \"Cuban\", \n",
    "             5: \"Dominican\", 6: \"Costa Rican\", 7: \"Guatemalan\", 8: \"Honduran\", 9: \"Nicaraguan\",\n",
    "            10: \"Panamanian\", 11: \"Salvadorian\", 12: \"Other Central American\", 13: \"Argentinian\",\n",
    "            14: \"Bolivian\", 15: \"Chilean\", 16: \"Colombian\", 17: \"Ecuadorian\", 18: \"Paraguayan\",\n",
    "            19: \"Peruvian\", 20: \"Uruguayan\", 21: \"Venezuelan\", 22: \"Other South American\",\n",
    "            23: \"Spaniard\", 24: \"All Other Spanish/Hispanic/Latino\"}\n",
    "df['hispanic_origin'] = df['HISP'].map(oldNewMap)\n",
    "\n",
    "print(\"Checkpoint 2.5\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Recode sex so male = 0 and female = 1\n",
    "if np.min(df['SEX']) > 0: #ensures that code won't be run if it's been recoded already\n",
    "\tdf['SEX'] = df['SEX'] - 1\n",
    "\n",
    "print(\"Checkpoint 2.6\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Create a new variable with labels for sex, to be used in exploratory analysis\n",
    "oldNewMap = {0: \"Male\", 1: \"Female\"}\n",
    "df['sex_recode'] = df['SEX'].map(oldNewMap)\n",
    "\n",
    "print(\"Checkpoint 2.7\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Create age ranges - 6 years in each range, plus another range for 77+\n",
    "df['age_recode'] = pd.cut(df['AGEP'],bins=[20,28.5,34.5,40.5,46.5,52.5,58.5,64.5,70.5,76.6,100],\n",
    "                          labels=['23-28','29-34','35-40','41-46','47-52','53-58','59-64','65-70','71-76','77+'])\n",
    "\n",
    "print(\"Checkpoint 2.8\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Recode detailed hispanic origin into smaller categories\n",
    "oldNewMap = {1: \"Not Spanish/Hispanic/Latino\", 2: \"Mexican\", 3: \"Puerto_Rican\", 4: \"Cuban\", \n",
    "            5: \"Other_Central_American\", 6: \"Other_Central_American\", 7: \"Other_Central_merican\", \n",
    "            8: \"Other_Central_American\", 9: \"Other_Central_American\", 10: \"Other_Central_American\", \n",
    "            11: \"Other_Central_American\", 12: \"Other_Central_American\", 13: \"South_American\",\n",
    "            14: \"South_American\", 15: \"South_American\", 16: \"South_American\", 17: \"South_American\", \n",
    "            18: \"South_American\", 19: \"South_American\", 20: \"South_American\", 21: \"South_American\", \n",
    "            22: \"South_American\", 23: \"Spaniard\", 24: \"All_Other_Hispanic\"}       \n",
    "df['hisp_recode'] = df['HISP'].map(oldNewMap)\n",
    "\n",
    "print(\"Checkpoint 3\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 3.1\n",
      "Memory usage: 2703872000 (kb)\n",
      "checkpoint 3.2\n",
      "Memory usage: 2703872000 (kb)\n",
      "checkpoint 3.3\n",
      "Memory usage: 2703872000 (kb)\n",
      "checkpoint 3.4\n",
      "Memory usage: 2703872000 (kb)\n",
      "checkpoint 4\n",
      "Memory usage: 2703872000 (kb)\n"
     ]
    }
   ],
   "source": [
    "# Creating the model \n",
    "\n",
    "# add intercept \n",
    "df['intercept'] = 1.0\n",
    "\n",
    "print(\"checkpoint 3.1\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# create dummy variables as tables\n",
    "\n",
    "# state dummy variables\n",
    "\n",
    "states_to_include = ['Alabama','Alaska','Arizona','Arkansas','California',\n",
    "                     'Colorado','Connecticut','Delaware','District_of_Columbia','Florida',\n",
    "                     'Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa',\n",
    "                     'Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts',\n",
    "                     'Michigan','Minnesota','Mississippi','Missouri','Montana',\n",
    "                     'Nebraska','Nevada','New_Hampshire','New_Jersey','New_Mexico',\n",
    "                     'New_York','North_Carolina','North_Dakota','Ohio','Oklahoma',\n",
    "                     'Oregon','Rhode_Island','South_Carolina','South_Dakota',\n",
    "                     'Tennessee','Texas','Utah','Vermont','Virginia','Washington',\n",
    "                     'West_Virginia','Wisconsin','Wyoming']\n",
    "\n",
    "dummy_states = pd.DataFrame(index=(states_to_include+['Pennsylvania']),columns=states_to_include)\n",
    "for state in states_to_include:\n",
    "\tdummy_states.set_value(state, state, 1)\n",
    "\n",
    "dummy_states = dummy_states.fillna(0)\n",
    "\n",
    "print(\"checkpoint 3.2\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# race dummy variables\n",
    "\n",
    "races_to_include = ['Black','Hispanic','Asian','Other']\n",
    "\n",
    "dummy_race = pd.DataFrame(index=(races_to_include+['White']),columns=races_to_include)\n",
    "for race in races_to_include:\n",
    "\tdummy_race.set_value(race, race, 1)\n",
    "\n",
    "dummy_race = dummy_race.fillna(0)\n",
    "\n",
    "print(\"checkpoint 3.3\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# hispanic origin\n",
    "\n",
    "hisp_to_include = ['Mexican','Puerto_Rican','Cuban','Other_Central_American',\n",
    "'South_American','Spaniard','All_Other_Hispanic']\n",
    "\n",
    "dummy_hisp = pd.DataFrame(index=(hisp_to_include+['Not Spanish/Hispanic/Latino']),columns=hisp_to_include)\n",
    "for hisp in hisp_to_include:\n",
    "\tdummy_hisp.set_value(hisp, hisp, 1)\n",
    "\n",
    "dummy_hisp = dummy_hisp.fillna(0)\n",
    "\n",
    "print(\"checkpoint 3.4\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Create interaction variable for sex and age\n",
    "df['sex_age'] = df['SEX'] * df['AGEP']\n",
    "\n",
    "print(\"checkpoint 4\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint 4.1\n",
      "Memory usage: 2703872000 (kb)\n",
      "checkpoint 4.2\n",
      "Memory usage: 3269197824 (kb)\n",
      "checkpoint 4.3\n",
      "Memory usage: 3269197824 (kb)\n",
      "checkpoint 4.4\n",
      "Memory usage: 3269197824 (kb)\n",
      "checkpoint 4.5\n",
      "Memory usage: 3269197824 (kb)\n",
      "checkpoint 4.6\n",
      "Memory usage: 4376788992 (kb)\n"
     ]
    }
   ],
   "source": [
    "# Join dummy variables to main df using SQL functions\n",
    "\n",
    "# open connection to SQLite database\n",
    "conn = sqlite3.connect('dat-test.db')\n",
    "\n",
    "print(\"checkpoint 4.1\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "df.to_sql('df_main',con=conn,if_exists='replace',index=False)\n",
    "\n",
    "print(\"checkpoint 4.2\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "dummy_states.to_sql('states',con=conn,if_exists='replace',index=True, index_label='State')\n",
    "\n",
    "print(\"checkpoint 4.3\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "dummy_race.to_sql('races',con=conn,if_exists='replace',index=True, index_label='Race')\n",
    "\n",
    "print(\"checkpoint 4.4\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "dummy_hisp.to_sql('hispanic_origins',con=conn,if_exists='replace',index=True, index_label='Hisp')\n",
    "\n",
    "print(\"checkpoint 4.5\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "model_df = sql.read_sql(\n",
    "\"\"\"\n",
    "SELECT a.intercept, a.AGEP, a.SEX, a.sex_age, r.Asian, r.Black, r.Other, h.Mexican,\n",
    "h.Puerto_Rican, h.Cuban, h.Spaniard, h.South_American, h.Other_Central_American, \n",
    "h.All_Other_Hispanic, s.Alabama, s.Alaska, s.Arizona, s.Arkansas, s.California,\n",
    "s.Colorado, s.Connecticut,s.Delaware,s.District_of_Columbia,s.Florida,\n",
    "s.Georgia,s.Hawaii,s.Idaho,s.Illinois,s.Indiana,s.Iowa,\n",
    "s.Kansas,s.Kentucky,s.Louisiana,s.Maine,s.Maryland,s.Massachusetts,\n",
    "s.Michigan,s.Minnesota,s.Mississippi,s.Missouri,s.Montana,\n",
    "s.Nebraska,s.Nevada,s.New_Hampshire,s.New_Jersey,s.New_Mexico,\n",
    "s.New_York,s.North_Carolina,s.North_Dakota,s.Ohio,s.Oklahoma,\n",
    "s.Oregon,s.Rhode_Island,s.South_Carolina,s.South_Dakota,\n",
    "s.Tennessee,s.Texas,s.Utah,s.Vermont,s.Virginia,s.Washington,\n",
    "s.West_Virginia,s.Wisconsin,s.Wyoming, a.science_degree, a.science_occupation, a.POBP\n",
    "FROM df_main as a\n",
    "JOIN states as s\n",
    "ON a.State = s.State\n",
    "JOIN races as r\n",
    "ON a.race_recode = r.Race\n",
    "JOIN hispanic_origins as h\n",
    "on a.hisp_recode = h.Hisp\n",
    "WHERE a.AGEP > 22 and a.POBP < 60\n",
    "\"\"\", con=conn)\n",
    "\n",
    "print(\"checkpoint 4.6\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-224bcf7f4d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Fit final degree model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlm_final_degree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mlm_final_degree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_cols_degree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'science_degree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit final occupation model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelinkles/ENTER/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[0;32m-> 1142\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelinkles/ENTER/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelinkles/ENTER/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 54\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# create models\n",
    "\n",
    "train_cols_degree = ['intercept','AGEP','SEX','sex_age','Asian','Black','Other',\n",
    "'Mexican','Puerto_Rican','Cuban','Spaniard','South_American',\n",
    "'Other_Central_American','All_Other_Hispanic'] + states_to_include\n",
    "\n",
    "train_cols_occ = ['intercept','AGEP','SEX','sex_age','Asian','Black','Other',\n",
    "'Mexican','Puerto_Rican','Cuban','Spaniard','South_American',\n",
    "'Other_Central_American','All_Other_Hispanic']\n",
    "\n",
    "# Fit final degree model\n",
    "lm_final_degree = LogisticRegression()\n",
    "lm_final_degree.fit(model_df[train_cols_degree],model_df['science_degree'])\n",
    "\n",
    "# Fit final occupation model\n",
    "# include only the subset of the original sample that has science degrees\n",
    "df_degree = model_df[model_df['science_degree']==1]\n",
    "lm_final_occ = LogisticRegression()\n",
    "lm_final_occ.fit(df_degree[train_cols_occ],df_degree['science_occupation'])\n",
    "\n",
    "print(\"checkpoint 5\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ROC curve for final degree model\n",
    "probas_degree = lm_final_degree.predict_proba(df[train_cols_degree])\n",
    "plt.plot(roc_curve(df[['science_degree']], probas_degree[:,1])[0], \n",
    "\troc_curve(df[['science_degree']], probas_degree[:,1])[1])\n",
    "plt.savefig('roc_degree.png')\n",
    "plt.close()\n",
    "del probas_degree\n",
    "\n",
    "# ROC Curve for final occupation model\n",
    "probas_occ = lm_final_occ.predict_proba(df[train_cols_occ])\n",
    "plt.plot(roc_curve(df[['science_occupation']], probas_occ[:,1])[0], \n",
    "\troc_curve(df[['science_occupation']], probas_occ[:,1])[1])\n",
    "plt.savefig('roc_occupation.png')\n",
    "plt.close()\n",
    "del probas_occ\n",
    "\n",
    "# fit all in statsmodels for confidence intervals\n",
    "\n",
    "# fit degree model\n",
    "logit_degree = sm.Logit(df['science_degree'], df[train_cols_degree]) \n",
    "\n",
    "# create dataframe of CIs\n",
    "result_degree = logit_degree.fit()\n",
    "params_degree = result_degree.params\n",
    "conf_degree = np.exp(result_degree.conf_int())\n",
    "conf_degree['OR'] = np.exp(params_degree)\n",
    "conf_degree.columns = ['2.5%', '97.5%', 'OR']\n",
    "\n",
    "del logit_degree\n",
    "del result_degree\n",
    "del params_degree\n",
    "\n",
    "print(\"checkpoint 6\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# add error column to degree CI dataframe, for use in plotting error bars\n",
    "conf_degree['error'] = conf_degree['97.5%'] - conf_degree['OR']\n",
    "race_odds_ratios = conf_degree[4:14]\n",
    "                            \n",
    "# add a new row for reference category\n",
    "race_odds_ratios.loc['White'] = [1,1,1,0]\n",
    "race_odds_ratios = race_odds_ratios.sort_values(by='OR', ascending=True)\n",
    "\n",
    "# fit occupation model\n",
    "logit_occ = sm.Logit(df_degree['science_occupation'], df_degree[train_cols_occ]) \n",
    "\n",
    "# create dataframe of CIs\n",
    "result_occ = logit_occ.fit()\n",
    "params_occ = result_occ.params\n",
    "conf_occ = np.exp(result_occ.conf_int())\n",
    "conf_occ['OR'] = np.exp(params_occ)\n",
    "conf_occ.columns = ['2.5%', '97.5%', 'OR']\n",
    "\n",
    "del logit_occ\n",
    "del result_occ\n",
    "del params_occ\n",
    "\n",
    "# add error column to ocupation CI dataframe, for use in plotting error bars\n",
    "conf_occ['error'] = conf_occ['97.5%'] - conf_occ['OR']\n",
    "race_odds_ratios_occ = conf_occ[4:14]\n",
    "\n",
    "# add a new row for reference category\n",
    "race_odds_ratios.loc['White'] = [1,1,1,0]\n",
    "race_odds_ratios_occ = race_odds_ratios_occ.sort_values(by='OR', ascending=True)                               \n",
    "\n",
    "print(\"checkpoint 7\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "\n",
    "# Graph odds ratios for science degree\n",
    "ind = np.arange(len(race_odds_ratios)) # how many bars\n",
    "width = 0.7 # width of bars\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, race_odds_ratios['OR'], width, color='lightblue', xerr=race_odds_ratios['error'])\n",
    "plt.title('Odds Ratios for Science Degree')\n",
    "plt.yticks(ind + width/2., race_odds_ratios.index.tolist()) # add category labels\n",
    "plt.xscale('log') # plot on log scale\n",
    "ax.get_xaxis().set_major_formatter(ScalarFormatter()) # convert x axis labels to scalar format\n",
    "plt.xticks([0.5,1,2,3]) # add ticks at these values\n",
    "plt.savefig('odds_ratios_race_degree.png')\n",
    "plt.close()\n",
    "\n",
    "# Graph odds ratios for science degree\n",
    "ind = np.arange(len(race_odds_ratios_occ)) # how many bars\n",
    "width = 0.7 # width of bars\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, race_odds_ratios_occ['OR'], width, color='lightblue', xerr=race_odds_ratios_occ['error'])\n",
    "plt.title('Odds Ratios for Getting a STEM Job with a STEM Degree')\n",
    "plt.yticks(ind + width/2., race_odds_ratios.index.tolist()) # add category labels\n",
    "plt.xscale('log') # plot on log scale\n",
    "ax.get_xaxis().set_major_formatter(ScalarFormatter()) # convert x axis labels to scalar format\n",
    "plt.xticks([0.5,1,2,3]) # add ticks at these values\n",
    "plt.savefig('odds_ratios_race_occupation.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"checkpoint 8\")\n",
    "print('Memory usage: %s (kb)' % resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
